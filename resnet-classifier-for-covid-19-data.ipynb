{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2 #image processing library\nimport glob #finding files\n\n#Pytorch Machine Learning Library\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader, random_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T05:16:53.902160Z","iopub.execute_input":"2021-07-15T05:16:53.902541Z","iopub.status.idle":"2021-07-15T05:16:53.906381Z","shell.execute_reply.started":"2021-07-15T05:16:53.902506Z","shell.execute_reply":"2021-07-15T05:16:53.905774Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = \"../input/siim-covid19-dataset-256px-jpg/256px/train/train/\"\nTEST_PATH = \"../input/siim-covid19-dataset-256px-jpg/256px/test/test/\"\none_hot = ['Atypical Appearance', 'Indeterminate Appearance', 'Negative for Pneumonia', 'Typical Appearance']\n\ntrain = pd.read_csv(\"../input/siim-covid19-dataset-256px-jpg/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T05:16:57.626145Z","iopub.execute_input":"2021-07-15T05:16:57.626653Z","iopub.status.idle":"2021-07-15T05:16:57.656960Z","shell.execute_reply.started":"2021-07-15T05:16:57.626607Z","shell.execute_reply":"2021-07-15T05:16:57.656077Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Saving and Preprocessing COVID-19 Data","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"#Creating Labels from Data Frame\ntrain_labels = pd.get_dummies(train.label_id).values\n\n#Creating array of images\ntrain_imgs = None\nfor img_id, study_id in train[['ImageInstanceUID', 'StudyInstanceUID']].values:\n    filepath = glob.glob(TRAIN_PATH + study_id + \"*\" + img_id + \".jpg\")[0]\n    if train_imgs is not None:\n        train_imgs = np.concatenate((train_imgs, np.array([cv2.imread(filepath)])))\n    else:\n        train_imgs = np.array([cv2.imread(filepath)])\n\nnp.save('training_labels', train_labels)\nnp.save('training_images', train_imgs)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T02:37:04.272909Z","iopub.execute_input":"2021-07-14T02:37:04.273380Z","iopub.status.idle":"2021-07-14T03:12:25.472571Z","shell.execute_reply.started":"2021-07-14T02:37:04.273335Z","shell.execute_reply":"2021-07-14T03:12:25.471478Z"},"_kg_hide-input":true,"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data Since Preprocessing Images is Time Consuming","metadata":{}},{"cell_type":"code","source":"train_labels = np.load('training_labels.npy')\ntrain_imgs = np.load('training_images.npy')\nprint(train_labels.shape)\nprint(train_imgs.shape)\n\ntrain_dataset = TensorDataset(Tensor(train_images), Tensor(train_labels))\ntrain_set, val_set = random_split(train_dataset, [5334, 1000])\ntrain_loader = DataLoader(train_set, batch_size=128, shuffle=True, drop_last=False, pin_memory=True, num_workers=4)\nval_loader = DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T05:17:01.368208Z","iopub.execute_input":"2021-07-15T05:17:01.368528Z","iopub.status.idle":"2021-07-15T05:17:01.384497Z","shell.execute_reply.started":"2021-07-15T05:17:01.368500Z","shell.execute_reply":"2021-07-15T05:17:01.382901Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-8c657e464cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_labels.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_images.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_labels.npy'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'training_labels.npy'","output_type":"error"}]},{"cell_type":"markdown","source":"# ResNet Implementation","metadata":{}},{"cell_type":"code","source":"#Activation Functions\nact_fn_by_name = {\n    \"tanh\": nn.Tanh,\n    \"relu\": nn.ReLU,\n    \"leakyrelu\": nn.LeakyReLU,\n    \"gelu\": nn.GELU\n}","metadata":{"execution":{"iopub.status.busy":"2021-07-14T19:16:35.589388Z","iopub.execute_input":"2021-07-14T19:16:35.589763Z","iopub.status.idle":"2021-07-14T19:16:35.595264Z","shell.execute_reply.started":"2021-07-14T19:16:35.589732Z","shell.execute_reply":"2021-07-14T19:16:35.594025Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Individual Blocks within the ResNet Architecture\nclass ResNetBlock(nn.Module):\n    def __init__(self, c_in, act_fn, c_out=-1, downsample=False):\n        super().__init__()\n        if not downsample:\n            c_out = c_in\n        \n        #Neural Network representing F\n        self.net = nn.Sequential(\n            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not downsample else 2, bias=False),\n            nn.BatchNorm2d(c_out),\n            act_fun(),\n            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(c_out)\n        )\n        \n        #Downsampling network for the input in order to facilitate F(x) + x\n        self.downsample = nn.Conv2d(c_in, c_out, kernel_size=1, stride=2) if subsample else None\n        self.act_fn = act_fn()\n        \n    def forward(self, x):\n        z = self.net(x)\n        if self.downsample is not None:\n            x = self.downsample(x)\n        out = z + x\n        out = self.act_fn(out)\n        return out\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-14T19:16:56.000629Z","iopub.execute_input":"2021-07-14T19:16:56.001306Z","iopub.status.idle":"2021-07-14T19:16:56.011641Z","shell.execute_reply.started":"2021-07-14T19:16:56.001250Z","shell.execute_reply":"2021-07-14T19:16:56.010622Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#ResNet Model Implementation\nclass ResNet(nn.Module):\n    def __init__(self, num_blocks=[3, 3, 3, 3], c_hidden=[64, 128, 256, 1024], act_fn_name='relu'):\n        super().__init__()\n        self.num_blocks = num_blocks\n        self.c_hidden = c_hidden\n        self.act_fn = act_fn_by_name[act_fn_name]\n        self.act_fn_name = act_fn_name\n        self._create_netwwork()\n        self._init_params()\n    \n    def _create_network(self):\n        \n        self.input_net = nn.Sequential(\n            nn.Conv2d(3, self.c_hidden[0], kernel_size=7, padding=3, stride=2, bias=False),\n            nn.BatchNorm2d(self.c_hidden[0]),\n            nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n            self.act_fn()\n        )\n        \n        blocks = []\n        for block_idx, block_count in enumerate(self.num_blocks):\n            for bc in range(block_count):\n                downsample = (bc == 0 and block_idx > 0)\n                blocks.append(\n                    ResNetBlock(c_in=self.c_hidden[block_idx if not downsample else (block_idx - 1)],\n                                act_fn=self.act_fn,\n                                c_out=c_hidden[block_idx],\n                                downsample=downsample))\n        self.blocks = nn.Sequential(*blocks)\n        \n        self.output_net = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1, 1)),\n            nn.Flatten(),\n            nn.Linear(c_hidden[-1], self.num_classes)\n        )\n    \n    def _init_params(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=self.act_fn_name)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        x = self.input_net(x)\n        x = self.blocks(x)\n        x = self.output_net(x)\n        return x\n            \n                \n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T19:17:01.319863Z","iopub.execute_input":"2021-07-14T19:17:01.320308Z","iopub.status.idle":"2021-07-14T19:17:01.337916Z","shell.execute_reply.started":"2021-07-14T19:17:01.320264Z","shell.execute_reply":"2021-07-14T19:17:01.336176Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Finding a Device\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(\"Device\", device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, nb_epochs, lr=0.01):\n    model.to(device)\n    loss_module = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    for epoch in range(nb_epochs):\n        #Training the model on the given batch\n        train_losses = []\n        for batch in train_loader:\n            x, y = batch\n            x, y = x.to(device), y.to(device)\n            #Calculating forward pass of the model\n            output = model(x)\n            \n            #Calculating loss\n            loss = loss_module(output, y)\n            train_losses.append(loss)\n            #Cleaning gradients\n            optimizer.zero_grad()\n            \n            #Backwward propagation of partial gradients\n            loss_module.backwward()\n            optimizer.step()\n        #Same steps, but calculating the validation loss\n        val_losses = []\n        for batch in val_loader:\n            x, y = batch\n            x, y = x.to(device), y.to(device)\n            loss = loss_module(model(x), y)\n            val_losses.append(loss)\n        \n        print(\"Epoch: \" + str(epoch + 1) + \" Train Loss: \" + str(torch.tensor(train_losses).mean()) + \" Validation Loss: \" + str(torch.tensor(val_losses).mean()))                ","metadata":{},"execution_count":null,"outputs":[]}]}