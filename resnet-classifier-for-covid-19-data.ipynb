{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-15T05:16:53.902541Z",
     "iopub.status.busy": "2021-07-15T05:16:53.902160Z",
     "iopub.status.idle": "2021-07-15T05:16:53.906381Z",
     "shell.execute_reply": "2021-07-15T05:16:53.905774Z",
     "shell.execute_reply.started": "2021-07-15T05:16:53.902506Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import random\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2 # image processing library\n",
    "from PIL import Image # another image library\n",
    "import glob # finding files\n",
    "from tqdm.notebook import tqdm # progress bars\n",
    "\n",
    "# Pytorch Machine Learning Library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import gc\n",
    "\n",
    "TRAIN_PATH = \"../SIIM Dataset/224px/train/train/\"\n",
    "TEST_PATH = \"../SIIM Dataset/224px/test/test/\"\n",
    "CSV_PATH = \"../SIIM Dataset/train.csv\"\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class for loading the COVID Data with PyTorch functionality\n",
    "\n",
    "labels = ['Negative for Pneumonia', 'Indeterminate Appearance', 'Typical Appearance', 'Atypical Appearance']\n",
    "\n",
    "class SIIM_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Getting the image\n",
    "        self.data.head()\n",
    "        img_id, study_id = self.data[['ImageInstanceUID', 'StudyInstanceUID']].iloc[idx]\n",
    "        filepath = glob.glob(self.root_dir + study_id + \"*\" + img_id + \".jpg\")[0]\n",
    "        img = cv2.imread(filepath)\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        #Getting the label\n",
    "        label_str = self.data['label_id'].iloc[idx]\n",
    "        label = labels.index(label_str)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "    \n",
    "        return img, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data loaders that will be used during training\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.44099547, 0.51991787, 0.60964888], [0.22431996, 0.20356079, 0.26086323])\n",
    "                                    ])\n",
    "\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.RandomResizedCrop((32, 32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.44099547, 0.51991787, 0.60964888], [0.22431996, 0.20356079, 0.26086323])\n",
    "                                    ])\n",
    "val_dataset = SIIM_Dataset(CSV_PATH, TRAIN_PATH, transform=train_transform)\n",
    "train_dataset = SIIM_Dataset(CSV_PATH, TRAIN_PATH, transform=test_transform)\n",
    "\n",
    "set_seed(42)\n",
    "train_set, _ = random_split(train_dataset, [5334, 1000])\n",
    "set_seed(42)\n",
    "_, val_set = random_split(val_dataset, [5334, 1000])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, drop_last=False, pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T19:16:35.589763Z",
     "iopub.status.busy": "2021-07-14T19:16:35.589388Z",
     "iopub.status.idle": "2021-07-14T19:16:35.595264Z",
     "shell.execute_reply": "2021-07-14T19:16:35.594025Z",
     "shell.execute_reply.started": "2021-07-14T19:16:35.589732Z"
    }
   },
   "outputs": [],
   "source": [
    "#Activation Functions\n",
    "act_fn_by_name = {\n",
    "    \"tanh\": nn.Tanh,\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"leakyrelu\": nn.LeakyReLU,\n",
    "    \"gelu\": nn.GELU\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T19:16:56.001306Z",
     "iopub.status.busy": "2021-07-14T19:16:56.000629Z",
     "iopub.status.idle": "2021-07-14T19:16:56.011641Z",
     "shell.execute_reply": "2021-07-14T19:16:56.010622Z",
     "shell.execute_reply.started": "2021-07-14T19:16:56.001250Z"
    }
   },
   "outputs": [],
   "source": [
    "#Individual Blocks within the ResNet Architecture\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, c_in, act_fn, c_out=-1, downsample=False):\n",
    "        super().__init__()\n",
    "        if not downsample:\n",
    "            c_out = c_in\n",
    "        \n",
    "        #Neural Network representing F\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not downsample else 2, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out)\n",
    "        )\n",
    "        \n",
    "        #Downsampling network for the input in order to facilitate F(x) + x\n",
    "        self.downsample = nn.Conv2d(c_in, c_out, kernel_size=1, stride=2) if downsample else None\n",
    "        self.act_fn = act_fn()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        out = z + x\n",
    "        out = self.act_fn(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T19:17:01.320308Z",
     "iopub.status.busy": "2021-07-14T19:17:01.319863Z",
     "iopub.status.idle": "2021-07-14T19:17:01.337916Z",
     "shell.execute_reply": "2021-07-14T19:17:01.336176Z",
     "shell.execute_reply.started": "2021-07-14T19:17:01.320264Z"
    }
   },
   "outputs": [],
   "source": [
    "#ResNet Model Implementation\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_blocks=[3, 3, 3, 3, 3, ], c_hidden=[64, 128, 256, 1024, 2048], act_fn_name='relu'):\n",
    "        super().__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        self.c_hidden = c_hidden\n",
    "        self.num_classes = num_classes\n",
    "        self.act_fn = act_fn_by_name[act_fn_name]\n",
    "        self.act_fn_name = act_fn_name\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _create_network(self):\n",
    "        \n",
    "        self.input_net = nn.Sequential(\n",
    "            nn.Conv2d(3, self.c_hidden[0], kernel_size=7, padding=3, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(self.c_hidden[0]),\n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n",
    "            self.act_fn()\n",
    "        )\n",
    "        \n",
    "        blocks = []\n",
    "        for block_idx, block_count in enumerate(self.num_blocks):\n",
    "            for bc in range(block_count):\n",
    "                downsample = (bc == 0 and block_idx > 0)\n",
    "                blocks.append(\n",
    "                    ResNetBlock(c_in=self.c_hidden[block_idx if not downsample else (block_idx - 1)],\n",
    "                                act_fn=self.act_fn,\n",
    "                                c_out=self.c_hidden[block_idx],\n",
    "                                downsample=downsample))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.c_hidden[-1], self.num_classes)\n",
    "        )\n",
    "    \n",
    "    def _init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=self.act_fn_name)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_net(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.output_net(x)\n",
    "        return x\n",
    "            \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "# Finding a Device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, nb_epochs, lr=0.01):\n",
    "    model.to(device)\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    epoch_bar = tqdm(range(nb_epochs), desc=\"Epoch Progress\")\n",
    "    train_bar = tqdm(train_loader, desc=\"Training Batches\")\n",
    "    val_bar = tqdm(val_loader, desc=\"Validating Batches\")\n",
    "    for epoch in epoch_bar:\n",
    "        #Training the model on the given batch\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            train_bar.update()\n",
    "            x, y = batch\n",
    "            y = y.long()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            #Calculating forward pass of the model\n",
    "            output = model(x)\n",
    "            \n",
    "            #Calculating loss\n",
    "            loss = loss_module(output, y)\n",
    "            train_losses.append(loss.item())\n",
    "            #Cleaning gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Backwward propagation of partial gradients\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            gc.collect()\n",
    "        \n",
    "        train_bar.refresh()\n",
    "        #Same steps, but calculating the validation loss\n",
    "        val_losses = []\n",
    "        for batch in val_loader:\n",
    "            val_bar.update()\n",
    "            with torch.no_grad():\n",
    "                x, y = batch\n",
    "                y = y.long()\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                \n",
    "                output = model(x)\n",
    "                loss = loss_module(output, y)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                del x\n",
    "                del y\n",
    "                gc.collect()\n",
    "        \n",
    "        val_bar.refresh()\n",
    "        train_bar.reset()\n",
    "        val_bar.reset()\n",
    "        print(\"Epoch: \" + str(epoch + 1) + \" Train Loss: \" + str(torch.tensor(train_losses).mean()) + \" Validation Loss: \" + str(torch.tensor(val_losses).mean()))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee3fb9d346746eaa1b2006618dd710c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch Progress'), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7c6b9f714c4f05b5a96b898888d643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training Batches'), FloatProgress(value=0.0, max=42.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd3665f275b435eb27d62bdddf982d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating Batches'), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: tensor(10.6430) Validation Loss: tensor(2.3646)\n",
      "Epoch: 2 Train Loss: tensor(1.5907) Validation Loss: tensor(2.7268)\n",
      "Epoch: 3 Train Loss: tensor(1.5992) Validation Loss: tensor(2.2175)\n",
      "Epoch: 4 Train Loss: tensor(1.4435) Validation Loss: tensor(1.2679)\n",
      "Epoch: 5 Train Loss: tensor(1.3608) Validation Loss: tensor(1.2613)\n",
      "Epoch: 6 Train Loss: tensor(1.2839) Validation Loss: tensor(1.2787)\n",
      "Epoch: 7 Train Loss: tensor(1.3879) Validation Loss: tensor(1.5695)\n",
      "Epoch: 8 Train Loss: tensor(1.2648) Validation Loss: tensor(1.2554)\n",
      "Epoch: 9 Train Loss: tensor(1.2778) Validation Loss: tensor(1.8365)\n",
      "Epoch: 10 Train Loss: tensor(1.3634) Validation Loss: tensor(1.5861)\n",
      "Epoch: 11 Train Loss: tensor(1.2981) Validation Loss: tensor(1.3736)\n",
      "Epoch: 12 Train Loss: tensor(1.3044) Validation Loss: tensor(1.6469)\n",
      "Epoch: 13 Train Loss: tensor(1.2511) Validation Loss: tensor(1.2539)\n",
      "Epoch: 14 Train Loss: tensor(1.2254) Validation Loss: tensor(1.5061)\n",
      "Epoch: 15 Train Loss: tensor(1.2251) Validation Loss: tensor(1.2325)\n",
      "Epoch: 16 Train Loss: tensor(1.2569) Validation Loss: tensor(1.2400)\n",
      "Epoch: 17 Train Loss: tensor(1.2132) Validation Loss: tensor(1.4122)\n",
      "Epoch: 18 Train Loss: tensor(1.2134) Validation Loss: tensor(1.2316)\n",
      "Epoch: 19 Train Loss: tensor(1.2325) Validation Loss: tensor(1.2289)\n",
      "Epoch: 20 Train Loss: tensor(1.1997) Validation Loss: tensor(1.3841)\n",
      "Epoch: 21 Train Loss: tensor(1.2104) Validation Loss: tensor(1.6814)\n",
      "Epoch: 22 Train Loss: tensor(1.3208) Validation Loss: tensor(1.6273)\n",
      "Epoch: 23 Train Loss: tensor(1.2621) Validation Loss: tensor(1.3453)\n",
      "Epoch: 24 Train Loss: tensor(1.2233) Validation Loss: tensor(1.3837)\n",
      "Epoch: 25 Train Loss: tensor(1.1900) Validation Loss: tensor(1.3581)\n",
      "Epoch: 26 Train Loss: tensor(1.1730) Validation Loss: tensor(1.2732)\n",
      "Epoch: 27 Train Loss: tensor(1.1873) Validation Loss: tensor(1.3448)\n",
      "Epoch: 28 Train Loss: tensor(1.1656) Validation Loss: tensor(1.2800)\n",
      "Epoch: 29 Train Loss: tensor(1.1603) Validation Loss: tensor(1.3816)\n",
      "Epoch: 30 Train Loss: tensor(1.1619) Validation Loss: tensor(1.2754)\n",
      "Epoch: 31 Train Loss: tensor(1.1458) Validation Loss: tensor(1.4704)\n",
      "Epoch: 32 Train Loss: tensor(1.1266) Validation Loss: tensor(1.3739)\n",
      "Epoch: 33 Train Loss: tensor(1.1286) Validation Loss: tensor(1.3520)\n",
      "Epoch: 34 Train Loss: tensor(1.1195) Validation Loss: tensor(1.2680)\n",
      "Epoch: 35 Train Loss: tensor(1.1151) Validation Loss: tensor(1.3393)\n",
      "Epoch: 36 Train Loss: tensor(1.1009) Validation Loss: tensor(1.3407)\n",
      "Epoch: 37 Train Loss: tensor(1.0893) Validation Loss: tensor(1.2592)\n",
      "Epoch: 38 Train Loss: tensor(1.0811) Validation Loss: tensor(1.2753)\n",
      "Epoch: 39 Train Loss: tensor(1.0717) Validation Loss: tensor(1.3309)\n",
      "Epoch: 40 Train Loss: tensor(1.0655) Validation Loss: tensor(1.2911)\n",
      "Epoch: 41 Train Loss: tensor(1.0679) Validation Loss: tensor(1.3539)\n",
      "Epoch: 42 Train Loss: tensor(1.0514) Validation Loss: tensor(1.3950)\n",
      "Epoch: 43 Train Loss: tensor(1.0307) Validation Loss: tensor(1.3387)\n",
      "Epoch: 44 Train Loss: tensor(1.0379) Validation Loss: tensor(1.3771)\n",
      "Epoch: 45 Train Loss: tensor(1.0393) Validation Loss: tensor(1.4949)\n",
      "Epoch: 46 Train Loss: tensor(1.0065) Validation Loss: tensor(1.3555)\n",
      "Epoch: 47 Train Loss: tensor(0.9902) Validation Loss: tensor(1.6418)\n",
      "Epoch: 48 Train Loss: tensor(0.9884) Validation Loss: tensor(1.6233)\n",
      "Epoch: 49 Train Loss: tensor(1.0145) Validation Loss: tensor(1.9393)\n",
      "Epoch: 50 Train Loss: tensor(0.9673) Validation Loss: tensor(1.7722)\n",
      "Epoch: 51 Train Loss: tensor(0.9290) Validation Loss: tensor(2.0591)\n",
      "Epoch: 52 Train Loss: tensor(0.9229) Validation Loss: tensor(1.7710)\n",
      "Epoch: 53 Train Loss: tensor(0.8904) Validation Loss: tensor(1.6957)\n",
      "Epoch: 54 Train Loss: tensor(0.8710) Validation Loss: tensor(1.7154)\n",
      "Epoch: 55 Train Loss: tensor(0.8416) Validation Loss: tensor(1.8195)\n",
      "Epoch: 56 Train Loss: tensor(0.8376) Validation Loss: tensor(1.9731)\n",
      "Epoch: 57 Train Loss: tensor(0.7881) Validation Loss: tensor(2.2070)\n",
      "Epoch: 58 Train Loss: tensor(0.7628) Validation Loss: tensor(1.9148)\n",
      "Epoch: 59 Train Loss: tensor(0.7083) Validation Loss: tensor(2.2847)\n",
      "Epoch: 60 Train Loss: tensor(0.6990) Validation Loss: tensor(2.1602)\n",
      "Epoch: 61 Train Loss: tensor(0.6473) Validation Loss: tensor(1.9090)\n",
      "Epoch: 62 Train Loss: tensor(0.6167) Validation Loss: tensor(2.1516)\n",
      "Epoch: 63 Train Loss: tensor(0.6159) Validation Loss: tensor(2.1524)\n",
      "Epoch: 64 Train Loss: tensor(0.5804) Validation Loss: tensor(2.5031)\n",
      "Epoch: 65 Train Loss: tensor(0.5581) Validation Loss: tensor(2.4981)\n",
      "Epoch: 66 Train Loss: tensor(0.4882) Validation Loss: tensor(2.5631)\n",
      "Epoch: 67 Train Loss: tensor(0.4417) Validation Loss: tensor(3.0504)\n",
      "Epoch: 68 Train Loss: tensor(0.4125) Validation Loss: tensor(3.0744)\n",
      "Epoch: 69 Train Loss: tensor(0.4122) Validation Loss: tensor(2.8182)\n",
      "Epoch: 70 Train Loss: tensor(0.3655) Validation Loss: tensor(2.9316)\n",
      "Epoch: 71 Train Loss: tensor(0.2790) Validation Loss: tensor(3.6830)\n",
      "Epoch: 72 Train Loss: tensor(0.3416) Validation Loss: tensor(3.0229)\n",
      "Epoch: 73 Train Loss: tensor(0.2866) Validation Loss: tensor(3.8131)\n",
      "Epoch: 74 Train Loss: tensor(0.2606) Validation Loss: tensor(3.9320)\n",
      "Epoch: 75 Train Loss: tensor(0.2486) Validation Loss: tensor(3.8169)\n",
      "Epoch: 76 Train Loss: tensor(0.2372) Validation Loss: tensor(4.1626)\n",
      "Epoch: 77 Train Loss: tensor(0.2683) Validation Loss: tensor(2.9947)\n",
      "Epoch: 78 Train Loss: tensor(0.2100) Validation Loss: tensor(4.5566)\n",
      "Epoch: 79 Train Loss: tensor(0.1569) Validation Loss: tensor(4.0644)\n",
      "Epoch: 80 Train Loss: tensor(0.1406) Validation Loss: tensor(4.6243)\n",
      "Epoch: 81 Train Loss: tensor(0.1170) Validation Loss: tensor(4.6375)\n",
      "Epoch: 82 Train Loss: tensor(0.1201) Validation Loss: tensor(5.2583)\n",
      "Epoch: 83 Train Loss: tensor(0.1140) Validation Loss: tensor(4.8442)\n",
      "Epoch: 84 Train Loss: tensor(0.1486) Validation Loss: tensor(4.6252)\n",
      "Epoch: 85 Train Loss: tensor(0.0912) Validation Loss: tensor(5.2392)\n",
      "Epoch: 86 Train Loss: tensor(0.0702) Validation Loss: tensor(4.9285)\n",
      "Epoch: 87 Train Loss: tensor(0.1394) Validation Loss: tensor(5.0125)\n",
      "Epoch: 88 Train Loss: tensor(0.1253) Validation Loss: tensor(5.0720)\n",
      "Epoch: 89 Train Loss: tensor(0.0673) Validation Loss: tensor(5.5172)\n",
      "Epoch: 90 Train Loss: tensor(0.0499) Validation Loss: tensor(5.9470)\n",
      "Epoch: 91 Train Loss: tensor(0.0480) Validation Loss: tensor(6.5677)\n",
      "Epoch: 92 Train Loss: tensor(0.0485) Validation Loss: tensor(6.0691)\n",
      "Epoch: 93 Train Loss: tensor(0.0694) Validation Loss: tensor(5.4336)\n",
      "Epoch: 94 Train Loss: tensor(0.0772) Validation Loss: tensor(6.0532)\n",
      "Epoch: 95 Train Loss: tensor(0.0634) Validation Loss: tensor(5.5852)\n",
      "Epoch: 96 Train Loss: tensor(0.0371) Validation Loss: tensor(6.2335)\n",
      "Epoch: 97 Train Loss: tensor(0.0362) Validation Loss: tensor(6.4446)\n",
      "Epoch: 98 Train Loss: tensor(0.0872) Validation Loss: tensor(5.6416)\n",
      "Epoch: 99 Train Loss: tensor(0.0731) Validation Loss: tensor(6.2888)\n",
      "Epoch: 100 Train Loss: tensor(0.0442) Validation Loss: tensor(6.4950)\n",
      "Epoch: 101 Train Loss: tensor(0.0382) Validation Loss: tensor(6.1557)\n",
      "Epoch: 102 Train Loss: tensor(0.0527) Validation Loss: tensor(6.3813)\n",
      "Epoch: 103 Train Loss: tensor(0.0562) Validation Loss: tensor(6.6174)\n",
      "Epoch: 104 Train Loss: tensor(0.0398) Validation Loss: tensor(6.6412)\n",
      "Epoch: 105 Train Loss: tensor(0.0458) Validation Loss: tensor(6.9051)\n",
      "Epoch: 106 Train Loss: tensor(0.0662) Validation Loss: tensor(6.6395)\n",
      "Epoch: 107 Train Loss: tensor(0.0493) Validation Loss: tensor(6.8290)\n",
      "Epoch: 108 Train Loss: tensor(0.0471) Validation Loss: tensor(6.3052)\n",
      "Epoch: 109 Train Loss: tensor(0.1223) Validation Loss: tensor(5.2483)\n",
      "Epoch: 110 Train Loss: tensor(0.1221) Validation Loss: tensor(5.6649)\n",
      "Epoch: 111 Train Loss: tensor(0.0498) Validation Loss: tensor(6.4897)\n",
      "Epoch: 112 Train Loss: tensor(0.0154) Validation Loss: tensor(7.1972)\n",
      "Epoch: 113 Train Loss: tensor(0.0454) Validation Loss: tensor(6.8127)\n",
      "Epoch: 114 Train Loss: tensor(0.0619) Validation Loss: tensor(7.2681)\n",
      "Epoch: 115 Train Loss: tensor(0.0399) Validation Loss: tensor(7.1683)\n",
      "Epoch: 116 Train Loss: tensor(0.0144) Validation Loss: tensor(8.1459)\n",
      "Epoch: 117 Train Loss: tensor(0.0089) Validation Loss: tensor(8.0122)\n",
      "Epoch: 118 Train Loss: tensor(0.0074) Validation Loss: tensor(7.7617)\n",
      "Epoch: 119 Train Loss: tensor(0.0221) Validation Loss: tensor(8.2847)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120 Train Loss: tensor(0.0398) Validation Loss: tensor(8.8621)\n",
      "Epoch: 121 Train Loss: tensor(0.0409) Validation Loss: tensor(8.0848)\n",
      "Epoch: 122 Train Loss: tensor(0.0313) Validation Loss: tensor(7.4432)\n",
      "Epoch: 123 Train Loss: tensor(0.0280) Validation Loss: tensor(7.6511)\n",
      "Epoch: 124 Train Loss: tensor(0.0246) Validation Loss: tensor(7.8841)\n",
      "Epoch: 125 Train Loss: tensor(0.0158) Validation Loss: tensor(7.4763)\n",
      "Epoch: 126 Train Loss: tensor(0.0242) Validation Loss: tensor(7.5216)\n",
      "Epoch: 127 Train Loss: tensor(0.0400) Validation Loss: tensor(7.0260)\n",
      "Epoch: 128 Train Loss: tensor(0.0528) Validation Loss: tensor(6.7457)\n",
      "Epoch: 129 Train Loss: tensor(0.0387) Validation Loss: tensor(6.0136)\n",
      "Epoch: 130 Train Loss: tensor(0.0340) Validation Loss: tensor(7.5248)\n",
      "Epoch: 131 Train Loss: tensor(0.0403) Validation Loss: tensor(8.0549)\n",
      "Epoch: 132 Train Loss: tensor(0.0460) Validation Loss: tensor(7.4406)\n",
      "Epoch: 133 Train Loss: tensor(0.0399) Validation Loss: tensor(7.1095)\n",
      "Epoch: 134 Train Loss: tensor(0.0283) Validation Loss: tensor(7.0005)\n",
      "Epoch: 135 Train Loss: tensor(0.0176) Validation Loss: tensor(7.3417)\n",
      "Epoch: 136 Train Loss: tensor(0.0148) Validation Loss: tensor(7.7065)\n",
      "Epoch: 137 Train Loss: tensor(0.0103) Validation Loss: tensor(7.6757)\n",
      "Epoch: 138 Train Loss: tensor(0.0140) Validation Loss: tensor(8.3831)\n",
      "Epoch: 139 Train Loss: tensor(0.0569) Validation Loss: tensor(7.4170)\n",
      "Epoch: 140 Train Loss: tensor(0.1031) Validation Loss: tensor(7.6998)\n",
      "Epoch: 141 Train Loss: tensor(0.0469) Validation Loss: tensor(7.3817)\n",
      "Epoch: 142 Train Loss: tensor(0.0463) Validation Loss: tensor(7.6630)\n",
      "Epoch: 143 Train Loss: tensor(0.0208) Validation Loss: tensor(8.0386)\n",
      "Epoch: 144 Train Loss: tensor(0.0154) Validation Loss: tensor(8.7435)\n",
      "Epoch: 145 Train Loss: tensor(0.0150) Validation Loss: tensor(8.2217)\n",
      "Epoch: 146 Train Loss: tensor(0.0132) Validation Loss: tensor(8.4786)\n",
      "Epoch: 147 Train Loss: tensor(0.0102) Validation Loss: tensor(8.4546)\n",
      "Epoch: 148 Train Loss: tensor(0.0303) Validation Loss: tensor(7.8143)\n",
      "Epoch: 149 Train Loss: tensor(0.0468) Validation Loss: tensor(7.9957)\n",
      "Epoch: 150 Train Loss: tensor(0.0864) Validation Loss: tensor(7.3115)\n",
      "Epoch: 151 Train Loss: tensor(0.0502) Validation Loss: tensor(7.5720)\n",
      "Epoch: 152 Train Loss: tensor(0.0271) Validation Loss: tensor(7.4190)\n",
      "Epoch: 153 Train Loss: tensor(0.0193) Validation Loss: tensor(7.7987)\n",
      "Epoch: 154 Train Loss: tensor(0.0083) Validation Loss: tensor(9.0484)\n",
      "Epoch: 155 Train Loss: tensor(0.0189) Validation Loss: tensor(8.5943)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f9b0ab8a670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kamesh/anaconda3/lib/python3.8/logging/__init__.py\", line 223, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-878337b28876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-9a37c8d5c7c2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, nb_epochs, lr)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#Same steps, but calculating the validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mval_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mchild_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-878337b28876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-9a37c8d5c7c2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, nb_epochs, lr)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#Same steps, but calculating the validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mval_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ResNet(4)\n",
    "train_model(model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
